\documentclass[a4paper,11pt]{article}

\usepackage[spanish]{babel}
\usepackage[utf8]{inputenc}
\usepackage{enumerate}
\usepackage{amsmath}
\usepackage{extsizes}
\usepackage{amssymb}
\usepackage{dsfont}
\usepackage{graphicx}
\usepackage{cancel}
\usepackage[usenames]{color}
\usepackage[dvipsnames]{xcolor}
\usepackage{accents}
\usepackage{flushend}
\usepackage{tikz}
\usepackage[LGR,T1]{fontenc}
\newcommand{\textgreek}[1]{\begingroup\fontencoding{LGR}\selectfont#1\endgroup}
\usetikzlibrary{arrows,automata}
\usepackage{multicol}
\setlength{\columnsep}{1cm}
\usepackage{listings}
\usepackage{graphics,graphicx, float} %para incluir imágenes y colocarlas



\usepackage[hidelinks]{hyperref}

\usepackage[vmargin=3cm,hmargin=3cm]{geometry}
%\setlength\parindent{0pt}

\setlength\parindent{0pt}


% Carpeta con las imágenes
%\graphicspath{{}}

\begin{document}


	\begin{center}
		\LARGE{\textbf{Nuevos Paradigmas de Interacción (2018-2019)} \\ Grado en Ingeniería Informática \\ Universidad de Granada }
		\vspace*{2.5cm}

		\rule{\textwidth}{1.6pt}\vspace*{-\baselineskip}\vspace*{4pt}
		\rule{\textwidth}{1.6pt}\vspace*{-\baselineskip}\vspace*{2pt}
		\vspace{0.5cm}

		\Huge{Memoria Técnica}

		\vspace{0.5cm}
		\rule{\textwidth}{1.6pt}\vspace*{-\baselineskip}\vspace*{2pt}
		\rule{\textwidth}{1.6pt}\vspace*{-\baselineskip}\vspace*{4pt}

		\vspace{2cm}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=1]{./Imagenes/logo_informatica.png}
	\label{fig:logougrciencias}
\end{figure}

		\vspace{4cm}
		\LARGE{Ignacio Aguilera Martos, Diego Asterio de Zaballa,\\ Manuel López Roldán \\ 16 de Diciembre de 2018 }

	\end{center}




\newpage

\tableofcontents

\newpage

\section{Idea, dispositivo y plataforma de desarrollo}

El proyecto que hemos querido desarrollar para la tercera práctica con integración de gestos es una continuación de nuestra idea de las dos primeras prácticas. Esta idea era la integración de un museo virtual lleno de cuadros a los que ahora se le suman modelos en 3D tales como esculturas o edificios que son manejados mediante gestos leídos con el dispositivo Leap Motion.

\vspace{10px}

El dispositivo escogido ha sido Leap Motion ya que es un dispositivo cuyo último SDK está pensado y desarrollado para la integración con las gafas de realidad virtual con lo que la integración con nuestra aplicación sería muy coherente. El dispositivo iría pegado a las gafas de tal forma que el usuario puede realizar los gestos sin necesidad de colocarse en un punto concreto o encima de algún elemento concreto puesto que los gestos son leídos directamente desde el Leap que apunta siempre a las manos por su localización en las gafas de VR. En este sentido la aplicación aún no está preparada para poder comunicarse con el dispositivo móvil puesto que es el componente que falta por desarrollar por el equipo de desarrolladores de Leap Motion Inc. y que ya han anunciado que están trabajando en esta integración. De momento el Leap puede emplearse como lo hemos integrado nosotros, es decir desde el ordenador, con el cuál si tiene una integración gestual sólida.

\vspace{10px}

Cabe decir que la plataforma que hemos elegido para el desarrollo de la aplicación ha sido Unity 3D. Esta decisión viene motivada por la facilidad de uso que nos da este entorno de desarrollo en el ámbito tridimensional así como la fácil integración de Leap Motion y reconocimiento de los datos provistos por el dispositivo ya que sus desarrolladores han implementado un Asset de Unity para facilitar el manejo del mismo. La integración por tanto con nuestra anterior idea del museo sería muy sencilla puesto que ambos proyectos están implementados en Unity y por tanto sólo se necesitaría diferenciarlos en dos escenas que serían cargadas convenientemente en función de si se quieren visualizar los cuadros o los modelos 3D.

\vspace{10px}

Una vez explicado esto, para desarrollar mejor la idea del proyecto, vamos a dar una introducción más específica sobre lo implementado para luego desgranar los aspectos técnicos del mismo.

\section{Proyecto}

El proyecto nos muestra nuestras manos reconocidas por el Leap Motion para poder interactuar adecuadamente con los objetos y poder ver cuándo los estamos tocando. La primera pantalla que se nos muestra es un menú tridimensional que es accedido presionando las opciones tal y como se muestra en los proyectos de ejemplo del Leap Motion. El menú nos da las cuatro opciones que tenemos para poder navegar e interactuar con las esculturas del museo que son: Observation Mode, Free World Mode, Play Mode y Exit.
\begin{itemize}
	\item Observation Mode: El Observation Mode nos permite visualizar la estatua en 3D como un modelo que se presenta en el centro de la escena y con la cual podemos interactuar gestualmente para desplazarla como queramos o hacerle zoom.
	\item Free World Mode: Este modo es el que nos permitirá visualizar la escena con realidad aumentada una vez que el SDK de Leap Motion tenga disponible la comunicación entre el dispositivo y el propio spartphone.
	\item Play Mode: Con este modo tenemos disponible un mundo con físicas que nos permite interactuar con elementos como cubos o la propia estatua para poder jugar desplazando los elementos, manipulándolos o tirándolos.
	\item Exit: Nos permite salir de la aplicación.
\end{itemize}

A continuación vamos a detallar más la estructura general de la escena para poder entrar posteriormente más en profundidad en cada modo y los gestos desarrollados.



\end{document}
